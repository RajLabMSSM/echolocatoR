---
title: "Bipolar Disorder GWAS: fine-mapping" 
author: "<h4>Author: <i>Brian M. Schilder</i></h4>" 
date: "<h4>Updated: <i>`r format( Sys.Date(), '%b-%d-%Y')`</i></h4>"
output:
  BiocStyle::html_document
vignette: >
    %\VignetteIndexEntry{BD GWAS} 
    %\usepackage[utf8]{inputenc}
    %\VignetteEngine{knitr::rmarkdown}
---

```{r setup, eval=FALSE} 
library(echolocatoR)  
### Set to wherever you want to store your data 
save_dir <- "/Desktop/BD_finemapping"
```

## Prepare `top_SNPs` data.frame   

Import the data.frame of containing lead/proxy SNPs 
to indicate where each GWAS locus is. 
 
```{r  Prepare `top_SNPs` data.frame, eval=FALSE}  
topSNPs <- echodata::import_topSNPs(
  topSS = file.path(save_dir,"my_loci.xlsx")
)
head(topSNPs)
```

## Path to full summary stats file  
 
To prepare the data for use with `echolocatoR` 
(without the need for manual column mapping) we must first munge the sumstats.

```{r fullSS, eval=FALSE}  
#### Set up paths ####
fullSS_path_vcf <- file.path(save_dir,"pgc-bip2021-all.vcf.tsv.gz")
target_path <- echotabix::construct_tabix_path(gsub(".vcf","",fullSS_path_vcf))
#### Look at the header of the pre-munged file ####
# MungeSumstats:::read_header(fullSS_path_vcf, n=3)
# header <- MungeSumstats::read_sumstats(fullSS_path_vcf, 
#                                        nrows = 100, 
#                                        standardise_headers = FALSE)
# header

#### Download file #####
if(!file.exists(fullSS_path_vcf)){
  utils::download.file("https://figshare.com/ndownloader/files/26603681",
                       fullSS_path_vcf)
}
#### Munge ####
if(!file.exists(target_path)){ 
  ## [Option 1]: MungeSumstats::format_sumstats
  ## Run the complete munging pipeline with additional QC
  ## Run with tabix_index=TRUE to index as well
  ## Correct the NGT column in the mapping file.
  ## Otherwise, NGT will be incorrectly be interpreted as N.
  # mapping_file <- subset(MungeSumstats:::sumstatsColHeaders,
  #                        Uncorrected!="NGT")
  # mss_out <- MungeSumstats::format_sumstats(path = fullSS_path_vcf,
  #                                           save_path = target_path,
  #                                           sort_coordinates = TRUE,
  #                                           log_folder = "~/Downloads/munge_logs",
  #                                           log_mungesumstats_msgs = TRUE,
  #                                           log_folder_ind = TRUE,
  #                                           tabix_index = TRUE,
  #                                           mapping_file = mapping_file)
  # target_path <- mss_out$sumstats
  
  ## [Option 2] MungeSumstats::write_sumstats 
  dat <- data.table::fread(fullSS_path_vcf, 
                           skip = "#CHROM") 
  ## Run just the column header mapping and write back to disk 
  dat <- echodata::mungesumstats_to_echolocatoR(dat = dat, 
                                                standardise_colnames = TRUE) 
  ## Add N column (necessary for most fine-mapping methods)
  dat[,N:=(NCAS+NCON)]
  ## Add "proportion_cases" column (needed for ABF)
  dat[,proportion_cases:=(NCAS/(NCAS+NCON))]
  ## Write and bgzip compress
  dat[,BP:=POS]
  target_path <- MungeSumstats::write_sumstats(sumstats_dt = dat,
                                               ref_genome = "hg19",
                                               save_path = target_path,
                                               tabix_index = TRUE,
                                               return_path = TRUE)  
  
  ## [Option 3]: echotabix::convert
  ### If you don't want to read the data into memory, 
  ## you can alternatively convert it with echotabix::convert
  ## Takes about the same amount of time as MungeSumstats::write_sumstats method
  # tabix_files <- echotabix::convert(fullSS_path = fullSS_path_munged, 
  #                                   start_col = "BP")
  # target_path <- tabix_files$path
  
  #### Free up memory in R by removing the full data ####
  remove(dat)
} else {
  message("Using pre-existing file: ",target_path)
} 
```

## Query subset

```{r, eval=FALSE}
loci <- topSNPs$Locus
#### Select one locus ####
topSNPs_locus <- topSNPs[loci[1],]

#### Construct a query to extract a single locus ####
window_size <- 1000000/2
query_granges <- echotabix::construct_query(
  query_chrom = topSNPs_locus$CHR, 
  query_start_pos = topSNPs_locus$POS - window_size, 
  query_end_pos = topSNPs_locus$POS + window_size)

#### Extract subset #####
dat_locus <- echotabix::query(target_path = target_path, 
                              query_granges = query_granges) 
### Preview the data ####
echodata::createDT(head(dat_locus))
```

## Get LD

`echoLD::get_LD` uses the coordinates from you locus-specific data to retrieve a subset of whole-sequencing sequencing data from the 1000 Genomes Project (in VCF format).

It then computes pairwise linkage disequilibrium (LD) between all SNPs in that 
subset.

```{r, eval=FALSE}
locus_dir <- file.path(save_dir, topSNPs_locus$Locus) 

LD_list  <- echoLD::get_LD(query_dat = dat_locus,
                           locus_dir = locus_dir,
                           superpopulation = "EUR",
                           LD_reference = "1KGphase3", 
                           force_new_LD = TRUE) 
```

## Fine-map

We can now run fine-mapping on the locus subset. You'll notice the the output
is the same `dat` object that was fed in, but with some new columns containing 
the results from each fine-mapping method that was run.

```{r, eval=FALSE}
dat2 <- echofinemap::multifinemap(dat = LD_list$DT,
                                  locus_dir = locus_dir,  
                                  LD_matrix = LD_list$LD, 
                                  finemap_methods=c("ABF","SUSIE","FINEMAP",
                                                    "POLYFUN_SUSIE","POLYFUN_FINEMAP"),
                                  n_causal = 5,
                                  force_new_finemap = TRUE)
# knitr::kable(head(dat2))
```

## Plot locus results

```{r, eval=FALSE} 
#### We'll need this column to color SNPs by LD with the lead SNP ####
dat2 <- echodata::assign_lead_snp(dat = dat2)

plot_list <- echoplot::plot_locus(dat = dat2, 
                                  LD_matrix = LD_list$LD,
                                  locus_dir = locus_dir,
                                  zoom = "4x",
                                  nott_epigenome = TRUE,
                                  nott_regulatory_rects = TRUE,
                                  nott_show_placseq = TRUE
                                  ) 
```


## Run full fine-mapping pipeline   

```{r Run fine-mapping pipeline, eval=FALSE}

t1 <- Sys.time()
results <- echolocatoR::finemap_loci(
 fullSS_path = target_path,
 topSNPs = topSNPs[11:30,],
 dataset_name = "BD_PGC2021",
 fullSS_genome_build = "hg19",
 bp_distance = 5e5L,
 # min_POS = topSNPs$min_pos,
 # max_POS = topSNPs$max_pos,
 n_causal = 5,
 finemap_methods=c("ABF","SUSIE","FINEMAP",
                   "POLYFUN_SUSIE","POLYFUN_FINEMAP"),
 munged = TRUE,
 LD_reference = "UKB",
 zoom = c("1x","4x"),
 plot_types = "fancy",
 nott_epigenome = TRUE, 
 nott_show_placseq = TRUE,
 results_dir = save_dir,
 conda_env="echoR_mini")
t2 <- Sys.time()
difftime(t2,t1)

```

### Summary plot

Make a plot summarising the fine-mapping results across all loci, 
and how they overlap with cell-type-specific epigenomic signatures
from Nott2019 and Corces2020.

```{r, eval=FALSE}
merged_dat <- echoannot::merge_finemapping_results(
  dataset = file.path(save_dir,"GWAS","BD_PGC2021"), 
  minimum_support = 0, 
  save_path = file.path(save_dir,"multifinemap_merged.csv.gz"))

gg_summary <- echoannot::super_summary_plot(
  merged_DT = merged_dat,
  snp_filter = "Support>0",
  save_plot = file.path(save_dir,"summary_plot.png"), 
  height = 10,
  width = 12)
```


<hr>

# Session info  

<details>

```{r Session Info, attr.output='style="max-height: 400px;"'}
utils::sessionInfo()
```

</details>

<br>

